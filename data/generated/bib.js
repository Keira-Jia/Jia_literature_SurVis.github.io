const generatedBibEntries = {
    "castillo-martinez_color_2020": {
        "abstract": "In this paper, the color index based thresholding method for background and foreground segmentation of plant images is presented. The proposed method is implemented with color index approach, for this purpose two color indexes are modified to provide better information about the green color of the plants. Two fixed threshold methods are proposed for the color indexes to discriminate between foreground (green plant) and background (soil). Three versions of the proposed method are presented, these are applied in plant images with controlled conditions and crop images with real environmental conditions. Experimental results demonstrate that the proposed method outperforms other algorithms used as comparative in plant images obtaining a segmentation error of 6.62 \u00b1 5.85\\% and a classification ratio of 1.93 \u00b1 0.05. Also, the proposed method provides better segmentation results in comparison with other well-known state-of-art algorithms in different crop images. Finally, the proposed method does not require of complex calculus and their implementations are straightforward on any device.",
        "author": "Castillo-Mart\u00ednez, Miguel \u00c1. and Gallegos-Funes, Francisco J. and Carvajal-G\u00e1mez, Blanca E. and Urriolagoitia-Sosa, Guillermo and Rosales-Silva, Alberto J.",
        "doi": "10.1016/j.compag.2020.105783",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\B5T6RQLA\\\\Castillo-Mart\u00ednez \u7b49 - 2020 - Color index based thresholding method for background and foreground segmentation of plant images.pdf:application/pdf",
        "issn": "01681699",
        "journal": "Computers and Electronics in Agriculture",
        "keywords": "type: Traditional Image Processing, evaluation: Quantitative, Color index, Threshold method, Segmentation, Green plants",
        "language": "en",
        "month": "nov,",
        "pages": "105783",
        "title": "Color index based thresholding method for background and foreground segmentation of plant images",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S0168169919306398",
        "urldate": "2025-05-15",
        "volume": "178",
        "year": "2020"
    },
    "dang_yoloweeds_2023": {
        "abstract": "Weeds are among the major threats to cotton production. Overreliance on herbicides for weed control has accelerated the evolution of herbicide-resistance in weeds and caused increasing concerns about environments, food safety and human health. Machine vision systems for automated/robotic weeding have received growing interest towards the realization of integrated, sustainable weed management. However, in the presence of unstructured field environments and significant biological variability of weeds, it remains a serious challenge to develop reliable weed identification and detection systems. A promising solution to address this challenge are the development of arge-scale, annotated image datasets of weeds specific to cropping systems and data-driven AI (artificial intelligence) models for weed detection. Among various deep learning architectures, a diversity of YOLO (You Only Look Once) detectors is well-suited for real-time application and has enjoyed great popularity for generic object detection. This study presents a new dataset (CottoWeedDet12) of weeds important to cotton production in the southern United States (U.S.); it consists of 5648 images of 12 weed classes with a total of 9370 bounding box annotations, collected under natural light conditions and at varied weed growth stages in cotton fields. A novel, comprehensive benchmark of 25 state-of-the-art YOLO object detectors of seven versions including YOLOv3, YOLOv4, Scaled-YOLOv4, YOLOR and YOLOv5, YOLOv6 and YOLOv7, has been established for weed detection on the dataset. Evaluated through the Monte-Caro cross validation with 5 replications, the detection accuracy in terms of mAP@0.5 ranged from 88.14 \\% by YOLOv3-tiny to 95.22 \\% by YOLOv4, and the accuracy in terms of mAP@[0.5:0.95] ranged from 68.18 \\% by YOLOv3-tiny to 89.72 \\% by Scaled-YOLOv4. All the YOLO models especially YOLOv5n and YOLOv5s have shown great potential for real-time weed detection, and data augmentation could increase weed detection accuracy. Both the weed detection dataset2 and software program codes for model benchmarking in this study are publicly available3, which will be to be valuable resources for promoting future research on big data and AI-empowered weed detection and control for cotton and potentially other crops.",
        "author": "Dang, Fengying and Chen, Dong and Lu, Yuzhen and Li, Zhaojian",
        "doi": "10.1016/j.compag.2023.107655",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\AWYRGFNU\\\\Dang \u7b49 - 2023 - YOLOWeeds A novel benchmark of YOLO object detectors for multi-class weed detection in cotton produ.pdf:application/pdf",
        "issn": "01681699",
        "journal": "Computers and Electronics in Agriculture",
        "keywords": "type: Deep Learning-Based Detection, evaluation: Quantitative, Cotton, Dataset, Deep learning, Machine vision, Precision agriculture, Weed detection",
        "language": "en",
        "month": "feb,",
        "pages": "107655",
        "shorttitle": "{YOLOWeeds}",
        "title": "{YOLOWeeds}: {A} novel benchmark of {YOLO} object detectors for multi-class weed detection in cotton production systems",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S0168169923000431",
        "urldate": "2025-05-15",
        "volume": "205",
        "year": "2023"
    },
    "espejo-garcia_towards_2020": {
        "abstract": "Reducing the use of pesticides through selective spraying is an important component towards a more sustainable computer-assisted agriculture. Weed identification at early growth stage contributes to reduced herbicide rates. However, while computer vision alongside deep learning have overcome the performance of approaches that use hand-crafted features, there are still some open challenges in the development of a reliable automatic plant identification system. These type of systems have to take into account different sources of variability, such as growth stages and soil conditions, with the added constraint of the limited size of usual datasets. This study proposes a novel crop/weed identification system that relies on a combination of fine-tuning pre-trained convolutional networks (Xception, Inception-Resnet, VGNets, Mobilenet and Densenet) with the \u201ctraditional\u201d machine learning classifiers (Support Vector Machines, XGBoost and Logistic Regression) trained with the previously deep extracted features. The aim of this approach was to avoid overfitting and to obtain a robust and consistent performance. To evaluate this approach, an open access dataset of two crop [tomato (Solanum lycopersicum L.) and cotton (Gossypium hirsutum L.)] and two weed species [black nightshade (Solanum nigrum L.) and velvetleaf (Abutilon theophrasti Medik.)] was generated. The pictures were taken by different production sites across Greece under natural variable light conditions from RGB cameras. The results revealed that a combination of fine-tuned Densenet and Support Vector Machine achieved a micro F1 score of 99.29\\% with a very low performance difference between train and test sets. Other evaluated approaches also obtained repeatedly more than 95\\% F1 score. Additionally, our results analysis provides some heuristics for designing transfer-learning based systems to avoid overfitting without decreasing performance.",
        "author": "Espejo-Garcia, Borja and Mylonas, Nikos and Athanasakos, Loukas and Fountas, Spyros and Vasilakoglou, Ioannis",
        "doi": "10.1016/j.compag.2020.105306",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\EGIQG3U9\\\\Espejo-Garcia \u7b49 - 2020 - Towards weeds identification assistance through transfer learning.pdf:application/pdf",
        "issn": "01681699",
        "journal": "Computers and Electronics in Agriculture",
        "keywords": "type: Deep Learning-Based Detection, evaluation: Quantitative, Weed identification, Deep learning, Transfer learning, Open data, Precision agriculture",
        "language": "en",
        "month": "apr,",
        "pages": "105306",
        "title": "Towards weeds identification assistance through transfer learning",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S0168169919319854",
        "urldate": "2025-05-15",
        "volume": "171",
        "year": "2020"
    },
    "ferentinos_deep_2018": {
        "abstract": "In this paper, convolutional neural network models were developed to perform plant disease detection and diagnosis using simple leaves images of healthy and diseased plants, through deep learning methodologies. Training of the models was performed with the use of an open database of 87,848 images, containing 25 different plants in a set of 58 distinct classes of [plant, disease] combinations, including healthy plants. Several model architectures were trained, with the best performance reaching a 99.53\\% success rate in identifying the corresponding [plant, disease] combination (or healthy plant). The signi\ufb01cantly high success rate makes the model a very useful advisory or early warning tool, and an approach that could be further expanded to support an integrated plant disease identi\ufb01cation system to operate in real cultivation conditions.",
        "author": "Ferentinos, Konstantinos P.",
        "doi": "10.1016/j.compag.2018.01.009",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\U8ZBGB6E\\\\Ferentinos - 2018 - Deep learning models for plant disease detection and diagnosis.pdf:application/pdf",
        "issn": "01681699",
        "journal": "Computers and Electronics in Agriculture",
        "keywords": "type: Deep Learning-Based Detection, evaluation: Quantitative, Convolutional neural networks, Machine learning, Artificial intelligence, Plant disease identification, Pattern recognition",
        "language": "en",
        "month": "feb,",
        "pages": "311--318",
        "title": "Deep learning models for plant disease detection and diagnosis",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S0168169917311742",
        "urldate": "2025-05-15",
        "volume": "145",
        "year": "2018"
    },
    "gao_deep_2020": {
        "abstract": "Background: Convolvulus sepium (hedge bindweed) detection in sugar beet fields remains a challenging problem due to variation in appearance of plants, illumination changes, foliage occlusions, and different growth stages under field conditions. Current approaches for weed and crop recognition, segmentation and detection rely predominantly on conventional machine-learning techniques that require a large set of hand-crafted features for modelling. These might fail to generalize over different fields and environments. Results: Here, we present an approach that develops a deep convolutional neural network (CNN) based on the tiny YOLOv3 architecture for C. sepium and sugar beet detection. We generated 2271 synthetic images, before combining these images with 452 field images to train the developed model. YOLO anchor box sizes were calculated from the training dataset using a k-means clustering approach. The resulting model was tested on 100 field images, showing that the combination of synthetic and original field images to train the developed model could improve the mean average precision (mAP) metric from 0.751 to 0.829 compared to using collected field images alone. We also compared the performance of the developed model with the YOLOv3 and Tiny YOLO models. The developed model achieved a better trade-off between accuracy and speed. Specifically, the average precisions (APs@IoU0.5) of C. sepium and sugar beet were 0.761 and 0.897 respectively with 6.48 ms inference time per image (800 \u00d7 1200) on a NVIDIA Titan X GPU environment. Conclusion: The developed model has the potential to be deployed on an embedded mobile platform like the Jetson TX for online weed detection and management due to its high-speed inference. It is recommendable to use synthetic images and empirical field images together in training stage to improve the performance of models.",
        "author": "Gao, Junfeng and French, Andrew P. and Pound, Michael P. and He, Yong and Pridmore, Tony P. and Pieters, Jan G.",
        "doi": "10.1186/s13007-020-00570-z",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\LFFKP6ZM\\\\Gao \u7b49 - 2020 - Deep convolutional neural networks for image-based Convolvulus sepium detection in sugar beet fields.pdf:application/pdf",
        "issn": "1746-4811",
        "journal": "Plant Methods",
        "keywords": "type: Deep Learning-Based Detection, evaluation: Quantitative, Precision farming, Deep learning, Weed detection, Synthetic images, Transfer learning",
        "language": "en",
        "month": "dec,",
        "number": "1",
        "pages": "29",
        "title": "Deep convolutional neural networks for image-based {Convolvulus} sepium detection in sugar beet fields",
        "type": "article",
        "url": "https://plantmethods.biomedcentral.com/articles/10.1186/s13007-020-00570-z",
        "urldate": "2025-05-15",
        "volume": "16",
        "year": "2020"
    },
    "hasan_survey_2021": {
        "abstract": "The rapid advances in Deep Learning (DL) techniques have enabled rapid detection, localisation, and recognition of objects from images or videos. DL techniques are now being used in many applications related to agriculture and farming. Automatic detection and classification of weeds can play an important role in weed management and so contribute to higher yields. Weed detection in crops from imagery is inherently a challenging problem because both weeds and crops have similar colours ('green-on-green'), and their shapes and texture can be very similar at the growth phase. Also, a crop in one setting can be considered a weed in another. In addition to their detection, the recognition of specific weed species is essential so that targeted controlling mechanisms (e.g. appropriate herbicides and correct doses) can be applied. In this paper, we review existing deep learning-based weed detection and classification techniques. We cover the detailed literature on four main procedures, i.e., data acquisition, dataset preparation, DL techniques employed for detection, location and classification of weeds in crops, and evaluation metrics approaches. We found that most studies applied supervised learning techniques, they achieved high classification accuracy by fine-tuning pre-trained models on any plant dataset, and past experiments have already achieved high accuracy when a large amount of labelled data is available.",
        "author": "Hasan, A. S. M. Mahmudul and Sohel, Ferdous and Diepeveen, Dean and Laga, Hamid and Jones, Michael G. K.",
        "doi": "10.48550/arXiv.2103.01415",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\DHWJA68G\\\\Hasan \u7b49 - 2021 - A Survey of Deep Learning Techniques for Weed Detection from Images.pdf:application/pdf",
        "keywords": "type: Review, evaluation: Literature Review, Deep learning, Weed detection, Weed classification, Machine Learning, Digital agriculture Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition",
        "language": "en",
        "month": "mar,",
        "note": "arXiv:2103.01415 [cs]",
        "publisher": "arXiv",
        "title": "A {Survey} of {Deep} {Learning} {Techniques} for {Weed} {Detection} from {Images}",
        "type": "misc",
        "url": "http://arxiv.org/abs/2103.01415",
        "urldate": "2025-05-15",
        "year": "2021"
    },
    "kotwal_agricultural_2023": {
        "abstract": "Plant disease computerization in agriculture areas an important for every country, as the population rate increases the demand for food supply also increases. Today, the signi\ufb01cant adaption of modern techniques and tools increases the accuracy of detection the plant disease. Identifying plant diseases in an early stage can reduce their spread. Early identifying is a beginning stage to \ufb01ght against disease spreading. For plenty of years, researchers have researched how to tackle the common disease effects amongst humans, animals, and plants. However, there are still many gaps are remaining to identify and explore. In recent years, there have been many researchers using Deep Learning (DL) and Transfer Learning (TL) technologies to detect agricultural diseases based on Machine Learning (ML) algorithms that were developed with the development of Arti\ufb01cial Intelligence (AI) technology. Many, DL architectures are carried out together with numerous diverse visualization strategies to perceive and label the features of plant diseases. Our take a look at additionally makes a specialty of how ML strategies had been moved from conventional ML to DL and additionally numerous overall performance metrics (F1-score, sensitivity, accuracy, etc) are used for the assessment of the architecture/strategies. Some challenges are \ufb01gure out while identifying the plant disease detection.",
        "author": "Kotwal, Jameer and Kashyap, Dr.Ramgopal and Pathan, Dr.Shafi",
        "doi": "10.1016/j.matpr.2023.02.370",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\B7PYK5FZ\\\\Kotwal \u7b49 - 2023 - Agricultural plant diseases identification From traditional approach to deep learning.pdf:application/pdf",
        "issn": "22147853",
        "journal": "Materials Today: Proceedings",
        "keywords": "type: Deep Learning-Based Detection, evaluation: Literature Review, Plant diseases, Convolution neural network (CNN), Deep learning",
        "language": "en",
        "pages": "344--356",
        "shorttitle": "Agricultural plant diseases identification",
        "title": "Agricultural plant diseases identification: {From} traditional approach to deep learning",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S2214785323009343",
        "urldate": "2025-05-15",
        "volume": "80",
        "year": "2023"
    },
    "leminen_madsen_open_2020": {
        "abstract": "For decades, signi\ufb01cant effort has been put into the development of plant detection and classi\ufb01cation algorithms. However, it has been dif\ufb01cult to compare the performance of the different algorithms, due to the lack of a common testbed, such as a public available annotated reference dataset. In this paper, we present the Open Plant Phenotype Database (OPPD), a public dataset for plant detection and plant classi\ufb01cation. The dataset contains 7590 RGB images of 47 plant species. Each species is cultivated under three different growth conditions, to provide a high degree of diversity in terms of visual appearance. The images are collected at the semi\ufb01eld area at Aarhus University, Research Centre Flakkebjerg, Denmark, using a customized data acquisition platform that provides well-illuminated images with a ground resolution of \u223c6.6 px mm\u22121. All images are annotated with plant species using the EPPO encoding system, bounding box annotations for detection and extraction of individual plants, applied growth conditions and time passed since seeding. Additionally, the individual plants have been tracked temporally and given unique IDs. The dataset is accompanied by two experiments for: (1) plant instance detection and (2) plant species classi\ufb01cation. The experiments introduce evaluation metrics and methods for the two tasks and provide baselines for future work on the data.",
        "author": "Leminen Madsen, Simon and Mathiassen, Solvejg Kopp and Dyrmann, Mads and Laursen, Morten Stigaard and Paz, Laura-Carlota and J\u00f8rgensen, Rasmus Nyholm",
        "copyright": "https://creativecommons.org/licenses/by/4.0/",
        "doi": "10.3390/rs12081246",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\MEPSG3ER\\\\Leminen Madsen \u7b49 - 2020 - Open Plant Phenotype Database of Common Weeds in Denmark.pdf:application/pdf",
        "issn": "2072-4292",
        "journal": "Remote Sensing",
        "keywords": "type: Dataset, evaluation: Quantitative, Dataset, Plant phenotyping, Plant seedlings, Weed control",
        "language": "en",
        "month": "apr,",
        "number": "8",
        "pages": "1246",
        "title": "Open {Plant} {Phenotype} {Database} of {Common} {Weeds} in {Denmark}",
        "type": "article",
        "url": "https://www.mdpi.com/2072-4292/12/8/1246",
        "urldate": "2025-05-15",
        "volume": "12",
        "year": "2020"
    },
    "liu_plant_2021": {
        "abstract": "Plant diseases and pests are important factors determining the yield and quality of plants. Plant diseases and pests identification can be carried out by means of digital image processing. In recent years, deep learning has made breakthroughs in the field of digital image processing, far superior to traditional methods. How to use deep learning technology to study plant diseases and pests identification has become a research issue of great concern to researchers. This review provides a definition of plant diseases and pests detection problem, puts forward a comparison with traditional plant diseases and pests detection methods. According to the difference of network structure, this study outlines the research on plant diseases and pests detection based on deep learning in recent years from three aspects of classification network, detection network and segmentation network, and the advantages and disadvantages of each method are summarized. Common datasets are introduced, and the performance of existing studies is compared. On this basis, this study discusses possible challenges in practical applications of plant diseases and pests detection based on deep learning. In addition, possible solutions and research ideas are proposed for the challenges, and several suggestions are given. Finally, this study gives the analysis and prospect of the future trend of plant diseases and pests detection based on deep learning.",
        "author": "Liu, Jun and Wang, Xuewei",
        "doi": "10.1186/s13007-021-00722-9",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\3HFCZY3E\\\\Liu\u548cWang - 2021 - Plant diseases and pests detection based on deep learning a review.pdf:application/pdf",
        "issn": "1746-4811",
        "journal": "Plant Methods",
        "keywords": "type: Review, evaluation: Literature Review, Deep learning, Convolutional neural network, Plant diseases and pests, Classification, Object detection, Segmentation",
        "language": "en",
        "month": "dec,",
        "number": "1",
        "pages": "22",
        "shorttitle": "Plant diseases and pests detection based on deep learning",
        "title": "Plant diseases and pests detection based on deep learning: a review",
        "type": "article",
        "url": "https://plantmethods.biomedcentral.com/articles/10.1186/s13007-021-00722-9",
        "urldate": "2025-05-15",
        "volume": "17",
        "year": "2021"
    },
    "wang_review_2019": {
        "abstract": "Weeds are among the major factors that could harm crop yield. With the advances in electronic and information technologies, machine vision combined with image processing techniques has become a promising tool for precise real-time weed and crop detection in the field, providing valuable sensing information for site-specific weed management. This review summarized the advances of weed detection using ground-based machine vision and image processing techniques. Concretely, the four procedures, i.e., pre-processing, segmentation, feature extraction and classification, for weed detection were presented in detail. To separate vegetation from background, different color indices and classification approaches like color index-based, threshold-based and learning-based ones, were developed. The difficulty of weed detection lies in discriminating between crops and weeds that often have similar properties. Generally, four categories of features, i.e., biological morphology, spectral features, visual textures and spatial contexts, were used for the task, which were discussed in this review. Application of conventional machine learning-based and recently developed deep learning-based approaches for weed detection were also presented. Finally, challenges and solutions provided by researchers for weed detection in the field, including occlusion and overlap of leaves, varying lighting conditions and different growth stages, were discussed.",
        "author": "Wang, Aichen and Zhang, Wen and Wei, Xinhua",
        "doi": "10.1016/j.compag.2019.02.005",
        "file": "PDF:C\\:\\\\Users\\\\jxx\\\\Zotero\\\\storage\\\\2RQ97C7V\\\\Wang \u7b49 - 2019 - A review on weed detection using ground-based machine vision and image processing techniques.pdf:application/pdf",
        "issn": "01681699",
        "journal": "Computers and Electronics in Agriculture",
        "keywords": "type: Review, evaluation: Literature Review, Weed detection, Machine vision, Image processing, Site-specific weed management, Precision agriculture",
        "language": "en",
        "month": "mar,",
        "pages": "226--240",
        "title": "A review on weed detection using ground-based machine vision and image processing techniques",
        "type": "article",
        "url": "https://linkinghub.elsevier.com/retrieve/pii/S0168169918317150",
        "urldate": "2025-05-15",
        "volume": "158",
        "year": "2019"
    }
};